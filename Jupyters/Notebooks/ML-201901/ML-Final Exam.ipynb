{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam - Machine Learning 2019-1\n",
    "Keep saving your notebook to guarantee that you don't lose your work. Whenever the end of the exam is announced save the current version. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Question (1.0)\n",
    "\n",
    "Consider the following kernel regression model:\n",
    "\n",
    "$$ f_w(x) = w\\phi(x) + w_0$$\n",
    "\n",
    "where \n",
    "\n",
    "$$ w=\\sum_{x_{i}\\in X}\\alpha_{i}\\phi(x_{i}) $$\n",
    "\n",
    "and $\\phi()$ is the feature map associated to a kernel $k(\\_,\\_)$\n",
    "\n",
    "Also consider the following loss function:\n",
    "\n",
    "$$E(w, x, y) = | y -  f_w(x))|$$\n",
    "\n",
    "Implement this model modifying the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(alpha, X, kernel, x):\n",
    "    '''\n",
    "     alpha:  vector of shape (n,) where n is the number of samples\n",
    "     X:      matrix of shape (n, 2) \n",
    "     kernel: a kernel function\n",
    "     x:      vector of shape (2,)\n",
    "    \n",
    "    returns:\n",
    "     the result of evaluating f_w(x)\n",
    "    '''\n",
    "    result = 0\n",
    "    for i in range(len(X)):\n",
    "        result += alpha[i]*kernel(X[i],x)\n",
    "    # your code here\n",
    "    #print(result)\n",
    "    return result\n",
    "\n",
    "def loss(alpha, X, kernel, x, y):\n",
    "    '''\n",
    "     alpha:  vector of shape (n,) where n is the number of samples\n",
    "     X:      matrix of shape (n, 2), training input samples\n",
    "     kernel: a kernel function\n",
    "     x:      vector of shape (2,), input sample \n",
    "     y:      scalar, target output sample\n",
    "    returns:\n",
    "     the result of evaluating the loss function for a sample (x, y)\n",
    "    '''\n",
    "    # your code here\n",
    "    perdida = np.abs(y-predict(alpha, X, kernel, x))\n",
    "    #print(perdida)\n",
    "    return perdida\n",
    "\n",
    "def loss_without_abs(alpha, X, kernel, x, y):\n",
    "    '''\n",
    "     alpha:  vector of shape (n,) where n is the number of samples\n",
    "     X:      matrix of shape (n, 2), training input samples\n",
    "     kernel: a kernel function\n",
    "     x:      vector of shape (2,), input sample \n",
    "     y:      scalar, target output sample\n",
    "    returns:\n",
    "     the result of evaluating the loss function for a sample (x, y)\n",
    "    '''\n",
    "    # your code here\n",
    "    perdida = (y-predict(alpha, X, kernel, x))\n",
    "    #print(perdida)\n",
    "    return perdida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Question (2.0)\n",
    "\n",
    "Write an expression to calculate the gradient of the loss with respect to the alpha parameter:\n",
    "\n",
    "$$ \\frac{\\partial E(w, x, y)}{\\partial \\alpha}= $$\n",
    "\n",
    "Write a function that calculates the gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_dalpha(alpha, X, kernel, x, y):\n",
    "    '''\n",
    "     alpha:  vector of shape (n,) where n is the number of samples\n",
    "     X:      matrix of shape (n, 2), training input samples\n",
    "     kernel: a kernel function\n",
    "     x:      vector of shape (2,), input sample \n",
    "     y:      scalar, target output sample\n",
    "    returns:\n",
    "     a vector of shape (n, ) where the position i corresponds to dE(x)/d\\alpha_i\n",
    "    '''\n",
    "    de = []\n",
    "    for i in range(len(X)):\n",
    "        if loss_without_abs(alpha, X, kernel, x, y) > 0:\n",
    "            de = np.append(de, (kernel(X[i], x))*-1)\n",
    "        else:\n",
    "            de = np.append(de, (kernel(X[i], x))*1)\n",
    "    # your code here\n",
    "    #print('Bien')\n",
    "    return de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Question (2.0)\n",
    "\n",
    "Implement batch gradient descent to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_vectorized(alpha, X, kernel, Y):\n",
    "    perdida_vector = 0\n",
    "    for i in range(len(Y)):\n",
    "        perdida_vector += loss(alpha, X, kernel, X[i], Y[i])\n",
    "        \n",
    "    perdida_vector = perdida_vector\n",
    "    #pint(perdida_vector)\n",
    "    return perdida_vector\n",
    "\n",
    "\n",
    "def de_dalpha_vectorized(alpha, X, kernel, Y):\n",
    "    derivada_vector = 0\n",
    "    for i in range(len(Y)):\n",
    "        derivada_vector += de_dalpha(alpha, X, kernel, X[i], Y[i])\n",
    "        \n",
    "    derivada_vector = derivada_vector\n",
    "    #nt(derivada_vector)\n",
    "    return derivada_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, eta, alpha_ini, kernel):\n",
    "    '''\n",
    "     X:      matrix of shape (n, 2), training input samples\n",
    "     Y:      vector of shape (n, ), training output samples\n",
    "     epochs: number of epochs\n",
    "     eta:    learning rate\n",
    "     alpha_ini:  vector of shape (n,), initial values of alpha\n",
    "     kernel: a kernel function\n",
    "    returns:\n",
    "     a tuple (alpha, losses) where:\n",
    "       alpha: vector of shape (n, ) with resulting alpha values\n",
    "       losses: a vector of shape (epochs, ) with the loss values for each epoch\n",
    "    '''\n",
    "    \n",
    "    alpha = alpha_ini\n",
    "    \n",
    "    losses = loss_vectorized(alpha, X, kernel, Y)\n",
    "    \n",
    "    for i in range(epochs-1):\n",
    "         alpha -= eta*de_dalpha_vectorized(alpha, X, kernel,Y)\n",
    "         losses = np.append(losses, loss_vectorized(alpha, X, kernel, Y))   \n",
    "            \n",
    "    # your code here\n",
    "    \n",
    "    #pint(len(losses))\n",
    "    return alpha, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05908375  0.00458     0.0156145  -0.015633  ]\n",
      "0.9583326249998905\n",
      "0.9756049999999603\n",
      "0.9428500624999478\n",
      "-1.0678212500003257\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def k1(x, y):\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def k2(x, y):\n",
    "    return (np.dot(x, y) + 1) ** 2\n",
    "\n",
    "X = [[-2, -1],\n",
    "     [-1, 3],\n",
    "     [2.5, -1.5],\n",
    "     [4, 2]]\n",
    "Y = [1, 1, 1, -1]\n",
    "alpha, losses = train(X, Y, 2000, 0.000001, [0.1, 0.0, -0.1, 0.0], k2)\n",
    "pl.plot(losses)\n",
    "print(alpha)\n",
    "for x in X:\n",
    "    print(predict(alpha, X, k2, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grader\n",
    "Run the following code to grade your exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  50 / 50\n"
     ]
    }
   ],
   "source": [
    "# Grader\n",
    "\n",
    "def k1(x, y):\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def k2(x, y):\n",
    "    return (np.dot(x, y) + 1) ** 2\n",
    "\n",
    "def test1():\n",
    "    X = [[-2, -1],\n",
    "         [-1, 3],\n",
    "         [2.5, -1.5],\n",
    "         [4, 2]]\n",
    "    Y = [-1, 1, 1, -1]\n",
    "    epsilon = 0.0001\n",
    "    test1 = [1.85 , 6.6 , 7.7 , 0.7]\n",
    "    test2 = [40.175 , 32.1 , 9.4 , 145.4]\n",
    "    alpha = [0.5, 0.4, -0.5, 0.3]\n",
    "    for i, x_i in enumerate(X):\n",
    "        if abs(loss(alpha, X, k1, x_i, Y[i]) - test1[i]) > epsilon:\n",
    "            return False\n",
    "    for i, x_i in enumerate(X):\n",
    "        if abs(loss(alpha, X, k2, x_i, Y[i]) - test2[i]) > epsilon:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def num_de_dalpha(alpha, X, kernel, x, y, epsilon):\n",
    "    deltas = np.identity(len(alpha)) * epsilon\n",
    "    de = np.zeros(len(alpha))\n",
    "    for i in range(len(alpha)):\n",
    "        de[i] = (loss(alpha + deltas[i, :], X, kernel, x, y) - \n",
    "                 loss(alpha - deltas[i, :], X, kernel, x, y)) / (2 * epsilon)\n",
    "    return de\n",
    "\n",
    "def test_de_dalpha(kernel):\n",
    "    if not test1():\n",
    "        return False\n",
    "    num_tests = 100\n",
    "    epsilon = 0.0001\n",
    "    X = [[-2, -1],\n",
    "         [-1, 3],\n",
    "         [2.5, -1.5],\n",
    "         [4, 2]]\n",
    "    for i in range(num_tests):\n",
    "        talpha = np.random.randn(len(X))\n",
    "        tx = np.random.randn(2)\n",
    "        ty = np.random.randn(1)\n",
    "        if np.linalg.norm(de_dalpha(talpha, X, kernel, tx, ty) - \n",
    "                          num_de_dalpha(talpha, X, kernel, tx, ty, epsilon)) > epsilon:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def test2():\n",
    "    return test_de_dalpha(k1) and test_de_dalpha(k2)\n",
    "\n",
    "def evaluate_loss(alpha, X, kernel, X_test, Y_test):\n",
    "    result = 0\n",
    "    for i, x in enumerate(X_test):\n",
    "        result += loss(alpha, X, kernel, x, Y_test[i])\n",
    "    return result\n",
    "\n",
    "def test3():\n",
    "    if not test1():\n",
    "        return False\n",
    "    X = [[-2, -1],\n",
    "         [-1, 3],\n",
    "         [2.5, -1.5],\n",
    "         [4, 2]]\n",
    "    Y = [1, 1, 1, -1]\n",
    "    alpha, losses = train(X, Y, 2000, 0.000001, [0.1, 0.0, -0.1, 0.0], k2)\n",
    "    loss = evaluate_loss(alpha, X, k2, X, Y)\n",
    "    if loss != losses[-1]:\n",
    "        return False\n",
    "    if loss < 5.0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    alpha, losses = train(X, Y, 300, 0.001, [1, -2, 3, 0.0], k1)\n",
    "    loss = evaluate_loss(alpha, X, k1, X, Y)\n",
    "    if loss != losses[-1]:\n",
    "        return False\n",
    "    if loss < 5.0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evaluation():\n",
    "    score = 0 \n",
    "    for test, sc in [(test1, 10), (test2, 20), (test3, 20)]:\n",
    "        if test():\n",
    "            score += sc\n",
    "    return score\n",
    "\n",
    "print(\"Score: \", evaluation(), \"/ 50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

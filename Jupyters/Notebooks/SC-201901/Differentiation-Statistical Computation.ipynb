{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation - Homework\n",
    "\n",
    "__Métodos Intensivos de Computación Estadística__\n",
    "\n",
    "Juan Sebastián Corredor Rodriguez - jucorredorr@unal.edu.co\n",
    "\n",
    "See my [Github Account](https://github.com/juanse1608) to know more about me and my projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Los datos del archivo de Binary Matrix abstracts.csv contiene la matrix document-término del conjunto de datos de abstracts de la tarea 1. Asuma la dimensión $m$ y haga un anáalisis de compontes principales y estime los vectores $\\theta_i$ donde $i = 1, \\dots N$ dados por las primeras $m$ componentes principales. Use las herramientas de diferenciación automática y numérica disponibles en su lenguaje de programación de preferencia. Incluya todos sus códigos por separado.\n",
    "\n",
    "Let's do the exercise with $m=5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the required libraries\n",
    "import pandas as pd\n",
    "import numpy as npx\n",
    "import matplotlib.pyplot as plt\n",
    "import autograd as grad\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import autograd.numpy as np\n",
    "from autograd import elementwise_grad as egrad \n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/JuanSebastianCorredorRodriguez/Documents/Git Repositories/Jupyters-2019/Jupyters/Datasets\n"
     ]
    }
   ],
   "source": [
    "%cd ../../Datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta = pd.read_csv('Binary_Matrix_abstracts.csv', index_col = 0)\n",
    "m = 5\n",
    "pca = PCA(n_components=m)\n",
    "pca.fit(dta)\n",
    "\n",
    "#Each row is one of the theta_i\n",
    "y = pca.fit_transform(dta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29518, 5)\n"
     ]
    }
   ],
   "source": [
    "#Let's see y\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that\n",
    "$$\\triangledown \\beta = \\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^{5}\\frac{\\partial l_{ij}}{\\partial \\beta_j} = \\sum_{i=1}^{5} (y_{ij} - \\pi_{ij}) \\begin{bmatrix} \\theta_i \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "The probabilities $\\pi_{ij}$ can be obtained with the cdf of the logistic distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Distribution\n",
    "def logistic_distribution(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric and Auto Differentiation\n",
    "\n",
    "Let's implements the Numeric and Auto-Diff with ``autograd`` library.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_ij(y_ij, pi_ij):\n",
    "    return y_ij* np.log(pi_ij) + (1-y_ij) * np.log(1-pi_ij)\n",
    "\n",
    "def probability_ij(eta):\n",
    "    return logistic_distribution(eta)\n",
    "\n",
    "def eta_function(a_j, theta_i, d_j):\n",
    "    return (np.dot(a_j.T, theta_i) - d_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto Differentiation\n",
    "a = grad.grad(log_ij, 1)\n",
    "b = grad.grad(probability_ij, 0)\n",
    "\n",
    "x = np.zeros(y.shape)\n",
    "\n",
    "#Se calcula la derivada para cada i,j de la matriz Y\n",
    "for i in range(len(y)):\n",
    "    theta_i = y[i,:]\n",
    "    a_j = np.ones((y.shape[1],1))\n",
    "    d_j = 0\n",
    "    for j in range(y.shape[1]):\n",
    "        eta_j = np.dot(a_j.T, theta_i) - d_j\n",
    "        x[i,j] = b(eta_j) * a(y[i,j], probability_ij(eta_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numeric Differentiation\n",
    "h = 0.0000001\n",
    "x_2 = np.zeros(y.shape)\n",
    "#Se calcula la derivada numérica\n",
    "\n",
    "for i in range(len(y)):\n",
    "    theta_i = y[i,:].T\n",
    "    a_j = np.ones((y.shape[1],1))\n",
    "    d_j = 0\n",
    "    for j in range(y.shape[1]):\n",
    "        eta_j = np.dot(a_j.T, theta_i) - d_j\n",
    "        b = 1/h * (probability_ij(eta_j+h) - probability_ij(eta_j))\n",
    "        a = 1/h * (log_ij(y[i,j], probability_ij(eta_j)+h)  -  log_ij(y[i,j], probability_ij(eta_j)))\n",
    "        x_2[i,j] = b*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The true derivate\n",
    "x_3 = np.zeros(y.shape)\n",
    "#Se calcula la derivada numérica\n",
    "\n",
    "for i in range(len(y)):\n",
    "    theta_i = y[i,:].T\n",
    "    a_j = np.ones((y.shape[1],1))\n",
    "    d_j = 0\n",
    "    for j in range(y.shape[1]):\n",
    "        eta_j = np.dot(a_j.T, theta_i) - d_j\n",
    "        p = probability_ij(eta_j)\n",
    "        x_3[i,j] = (y[i,j] - p)/(p*(1-p)) * np.exp(-eta_j)/np.power(np.exp(-eta_j)+1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric Differentiation take less time that Auto Differentiation but now let's look at the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Automatic Diff: 1.637656801626484e-27\n",
      "MSE Numeric Diff: 3.818927030738308e-09\n",
      "\n",
      "Automatic Differentiation MSE is smaller than Numeric Differentiation\n"
     ]
    }
   ],
   "source": [
    "#Let's see the MSE \n",
    "diff_auto = np.sum(np.power(x-x_3,2))\n",
    "diff_num = np.sum(np.power(x_2-x_3,2))\n",
    "print('MSE Automatic Diff: {}'.format(diff_auto))\n",
    "print('MSE Numeric Diff: {}'.format(diff_num))\n",
    "if diff_auto < diff_num:\n",
    "    print('\\nAutomatic Differentiation MSE is smaller than Numeric Differentiation')\n",
    "else:\n",
    "    print('\\nNumeric Differentiation MSE is smaller than Automatic Differentiation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Matrix\n",
    "\n",
    "Let's calculate the information matrix\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_eta_a = grad.grad(eta_function, 0)\n",
    "d_eta_d = grad.grad(eta_function, 2)\n",
    "J_1 = np.zeros((m+1,m+1,y.shape[0],y.shape[1]))\n",
    "J_2 = np.zeros((m+1,m+1,y.shape[0],y.shape[1]))\n",
    "J_3 = np.zeros((m+1,m+1,y.shape[0],y.shape[1]))\n",
    "\n",
    "for i in range(len(y)):\n",
    "    theta_i = y[i,:].T.reshape((y.shape[1], 1))\n",
    "    a_j = np.ones((y.shape[1], 1))\n",
    "    d_j = 0\n",
    "    T = np.append(theta_i,1).reshape((y.shape[1] + 1, 1))\n",
    "    for j in range(y.shape[1]):\n",
    "        J_1[:,:, i,j] = x[i,j]*np.dot(T,T.T)\n",
    "        J_2[:,:, i,j] = x_2[i,j]*np.dot(T,T.T)\n",
    "        J_3[:,:, i,j] = x_3[i,j]*np.dot(T,T.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_1_b1 = 0\n",
    "J_2_b1 = 0\n",
    "J_3_b1 = 0\n",
    "\n",
    "for i in range(len(y)):\n",
    "    J_1_b1 = J_1_b1 + J_1[:,:,i,1]\n",
    "    J_2_b1 = J_2_b1 + J_2[:,:,i,1]    \n",
    "    J_3_b1 = J_3_b1 + J_3[:,:,i,1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.697157874407051e-24\n",
      "8.93355401686857e-06\n",
      "9.697157874407051e-24\n"
     ]
    }
   ],
   "source": [
    "#Let's the MSE of Numeric adn Automatic\n",
    "print(np.sum(np.power(J_1_b1 - J_3_b1,2)))\n",
    "print(np.sum(np.power(J_2_b1 - J_3_b1,2)))\n",
    "print(np.sum(np.power(J_1_b1 - J_3_b1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear the superiority of Automatic Differentiation in terms of error against its rivals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
